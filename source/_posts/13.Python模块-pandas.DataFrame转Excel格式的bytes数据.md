---
title: Pythonæ¨¡å—-pandas.DataFrameè½¬Excelæ ¼å¼çš„bytesæ•°æ®
date: 2022-09-08 18:00:00
author: ChenyangGao
categories: é€šç”¨æ¨¡å—
tags: [Python, Module]
thumbnail: https://cdn.pixabay.com/photo/2013/12/10/18/22/green-tree-python-226553_1280.jpg

---

## èƒŒæ™¯

> [pandas](https://pandas.pydata.org) is an open source, [BSD-licensed](https://en.wikipedia.org/wiki/BSD_licenses) library providing high-performance, easy-to-use data structures and data analysis tools for the [Python](https://www.python.org/) programming language.

æ•°æ®åˆ†æå·¥å…·åŒ… <kbd>pandas</kbd>ï¼Œæ˜¯åˆ©ç”¨ <kbd>Python</kbd> è¿›è¡Œæ•°æ®åˆ†ææ—¶ï¼Œä¸€ä¸ªéš¾ä»¥å‰²èˆçš„é€‰é¡¹ã€‚å®ƒçš„å®˜æ–¹æ–‡æ¡£ [pandas/docs](https://pandas.pydata.org/docs/) ç¤ºä¾‹éå¸¸ä¸°å¯Œï¼Œè€Œä¸”å®ƒçš„ä½œè€… [Wes McKinney](https://wesmckinney.com) å¦å¤–è¿˜å†™äº†ä¸€æœ¬ä¹¦ [Python for Data Analysis](https://wesmckinney.com/book/)ï¼Œæˆªè‡³ç›®å‰å·²ç»æ›´æ–°åˆ°ç¬¬ 3 ç‰ˆï¼Œ[ğŸ‘†ç‚¹å‡»ä¸‹è½½](https://salttiger.com/python-for-data-analysis-3rd-edition/)ã€‚
ä¸­å›½å›½å†…ä¹Ÿæœ‰çƒ­å¿ƒç½‘å‹åšäº†å…è´¹çš„ç¿»è¯‘åˆ†äº«ï¼Œè¿™æ˜¯ç¬¬ 2 ç‰ˆï¼Œ[ç®€ä¹¦-ã€ŠPythonæ•°æ®åˆ†æã€‹2nd](https://www.jianshu.com/p/fad9e41c1a42)ã€‚
![Python for Data Analysis, 3rd Edition](https://learning.oreilly.com/library/cover/9781098104023/1200w/)

æˆ‘æ›¾ç»å®ç°è¿‡ä¸€ä¸ªå•æœºéƒ¨ç½²çš„ [ETL (extract, transform, load)](https://en.wikipedia.org/wiki/Extract,_transform,_load) ç¨‹åºï¼Œä¸‰ä¸ªæ­¥éª¤éƒ½åŸºäº <kbd>pandas</kbd> å®ç°ã€‚ä¸è¿‡è¿™ä¸ªç¨‹åºæœ€å¸¸ç”¨çš„åŠŸèƒ½ï¼Œå´ä»…ä»…æ˜¯å®šæ—¶è¯»å–ä¸€æ‰¹ [SQL](https://en.wikipedia.org/wiki/SQL)ï¼Œç„¶åå†™å…¥ [Excel](https://www.microsoft.com/en-us/microsoft-365/excel)ï¼Œæœ€åæŠŠè¿™äº› Excel æ–‡ä»¶ä½œä¸ºé‚®ä»¶é™„ä»¶è¿›è¡Œå‘é€ï¼ŒçœŸæ˜¯æ€é¸¡ç”¨ç‰›åˆ€ğŸ˜‚ã€‚

å…¶å®ï¼Œæˆ‘ä¸ªäººå¹¶ä¸å¤ªå–œæ¬¢ä½¿ç”¨ Excel æ–‡ä»¶ï¼Œå…ˆä¸è®º Excel é‚£ç¼“æ…¢çš„æ‰“å¼€é€Ÿåº¦ï¼Œå®ƒçš„ä¸€ä¸ªå·¥ä½œè¡¨æœ€å¤šä¹Ÿåªèƒ½æœ‰ **1048576**ï¼ˆ2^20ï¼‰ è¡Œå’Œ **16384**ï¼ˆ2^14ï¼‰ åˆ—ï¼Œå·¥ä½œè¡¨åå­—æœ€å¤š **31** ä¸ªå­—ç¬¦ã€‚æ‰€ä»¥åœ¨æˆ‘çœ‹æ¥ï¼Œ[CSV](https://en.wikipedia.org/wiki/Comma-separated_values) æ‰æ˜¯æ›´å¥½çš„é€‰é¡¹ã€‚

åœ¨é‚£ä¸ª `ETL` ä¸­ï¼Œåªå…è®¸ä»æ¯ä¸ªæºè¯»å–ä¸€ä¸ª <kbd>pandas</kbd> çš„ `DataFrame`ï¼Œä½†åœ¨è¾“å‡ºæ—¶ï¼Œå¯ä»¥æŠŠå¤šä¸ª `DataFrame` è¾“å‡ºåˆ°ä¸€ä¸ªç›®æ ‡é‡Œé¢ã€‚å¯¹äºä¸€ç§è¿™ç±»æƒ…å†µï¼Œå³æŠŠå¤šä¸ª `DataFrame` è¾“å‡ºåˆ°åŒä¸€ä¸ª `Excel` å·¥ä½œç°¿ï¼Œå¦‚æœè¿™ä¸ªç›®æ ‡ä¹‹åå†ä½œä¸ºä¸€ä¸ªæºæ—¶ï¼Œå°±ä¸å¥½å¤„ç†äº†ã€‚å¦‚æœè¿™æ˜¯æœ€ç»ˆçš„è¾“å‡ºï¼Œè€Œä¸æ˜¯ç®¡é“çš„ä¸€ä¸ªä¸­é—´ç¯èŠ‚ï¼Œå´æ˜¯å¯ä»¥æ¥å—çš„ã€‚

`Excel` æœ€å¤§çš„é—®é¢˜æ˜¯å·¥ä½œè¡¨çš„è§„æ¨¡æœ‰é™ï¼Œå¦‚æœä½ çš„è¡¨æ ¼çš„è§„æ ¼è¶…å‡º **1048576**Ã—**16384**ï¼Œä¹Ÿå°±æ˜¯è¿™ä¸ªçŸ©å½¢ä¸èƒ½æŠŠä½ æ•°æ®è¡¨æ ¼å®Œå…¨ç›–ä½ï¼Œä½ å°±å¾—å¯¹ `DataFrame` è¿›è¡Œæ‹†åˆ†ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä¸ªäººæ˜¯ä¸æ¨èåšæ‹†åˆ†çš„ã€‚æˆ‘çš„å»ºè®®æ˜¯ï¼Œä¸€ä¸ªå·¥ä½œç°¿ï¼Œåªå¼€ä¸€ä¸ªå·¥ä½œè¡¨ï¼Œå¦‚æœä¸€ä¸ªå·¥ä½œè¡¨å­˜å‚¨ä¸ä¸‹ï¼Œé‚£å°±ç”¨ `CSV` æˆ–è€… [hdf5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) æ ¼å¼ã€‚

<!--more-->

## ä»£ç å®ç°

> **TIPS** ä»£ç çš„æœ€æ–°ç‰ˆæœ¬åœ¨ [GitHub Gist](https://gist.github.com/ChenyangGao) ä¸­ç»´æŠ¤
> https://gist.github.com/ChenyangGao/6a3f6177ce8da748413ce304156588f9

æ–‡ä»¶åç§°æ˜¯ `pandas_to_excel_bytes.py`ï¼Œ<kbd>Python</kbd> å®ç°ä»£ç å¦‚ä¸‹ï¼š

```python pandas_to_excel_bytes.py
#!/usr/bin/env python3
# coding: utf-8

"""è¿™ä¸ªæ¨¡å—æä¾›äº†å·¥å…·å‡½æ•°ï¼Œå¯ä»¥æŠŠ `pandas` çš„ `DataFrame` è½¬æ¢æˆ
xlsx æ ¼å¼çš„ Excel æ–‡ä»¶çš„äºŒè¿›åˆ¶æ•°æ®
"""

__author__ = "ChenyangGao <https://chenyanggao.github.io/>"
__version__ = (0, 1)
__all__ = ["df_to_excel_bytes", "sql_to_excel_bytes"]

from concurrent.futures import ThreadPoolExecutor
from contextlib import contextmanager
from io import BytesIO 
from os import PathLike
from typing import cast, Final, Iterable, IO, TypeVar, Union
from types import MappingProxyType, MethodType
from warnings import warn

# å®‰è£… [pandas-stubs](https://pypi.org/project/pandas-stubs/) ä»¥é™æ€æ£€æŸ¥
from pandas import read_sql, DataFrame, ExcelWriter, RangeIndex


IO_T = TypeVar("IO_T", bytes, str)

# Excel çš„å·¥ä½œè¡¨åæœ‰ä¸€äº›éæ³•å­—ç¬¦ []:*?/\\ï¼Œéœ€è¦æŠŠå‡ºç°çš„éæ³•å­—ç¬¦å˜æˆåˆæ³•å­—ç¬¦ _
EXCEL_SHEETNAME_INVALID_CHARS_TRANSTABLE: Final[MappingProxyType] = \
    MappingProxyType(dict.fromkeys(map(ord, "[]:*?/\\"), "_"))

# xlsx æ ¼å¼çš„ Excel æ–‡ä»¶ï¼Œæœ€å¤§çš„è¡Œæ•°
SHEET_MAX_NROWS: Final[int] = 2 ** 20
# xlsx æ ¼å¼çš„ Excel æ–‡ä»¶ï¼Œæœ€å¤§çš„åˆ—æ•°
SHEET_MAX_NCOLS: Final[int] = 2 ** 14
# xlsx æ ¼å¼çš„ Excel æ–‡ä»¶ï¼Œå·¥ä½œè¡¨åæœ€å¤§çš„å­—ç¬¦æ•°
SHEETNAME_MAX_LENGTH: Final[int] = 31


def read_io(fio: IO[IO_T], /) -> IO_T:
    "ä»å¤´è¯»å–ä¸€ä¸ª IO å¯¹è±¡çš„æ•°æ®"
    pos: int = fio.tell()
    try:
        fio.seek(0)
        return fio.read()
    finally:
        fio.seek(pos)


@contextmanager
def ctx_df_to_excel_bytes(**kwargs):
    """ä¸Šä¸‹æ–‡ç®¡ç†å™¨ã€‚
    æŠŠ `pandas` çš„ `DataFrame` å¯¹è±¡è½¬æ¢æˆ xlsx æ ¼å¼çš„ Excel æ–‡ä»¶çš„å­—èŠ‚æ•°æ®

    :param kwargs: å…³é”®å­—å‚æ•°ä¼ ç»™ `pandas` çš„ `ExcelWriter` æ„é€ å™¨
        > è¯·å‚è€ƒ: pandas.io.Excel._base.ExcelWriter
        > https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.ExcelWriter.html
    :return: ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œè¿”å›ä¸€ä¸ª `pandas` çš„ `ExcelWriter` å¯¹è±¡ï¼Œ
        ä½†æ˜¯å¢åŠ äº† 3 ä¸ªå±æ€§ï¼š
        - bio: Excel æ•°æ®å°†è¢«å†™å…¥è¿™ä¸ª `io.Bytes` å¯¹è±¡
        - read: ä» `bio` ä¸­è¯»å– Excel æ•°æ®
        - write: æŠŠ `bio` ä¸­çš„ Excel æ•°æ®å†™å…¥ä¸€ä¸ªè·¯å¾„

    Example::
        >>> import pandas as pd
        >>> df = pd.DataFrame([[1,2],[3,4]])
        >>> with ctx_df_to_excel_bytes() as writer:
        ...     for i in range(10):
        ...         df.to_excel(writer, sheet_name=str(i), index=False)
        >>> data = writer.read()
        >>> df2 = pd.read_excel(data, sheet_name="5")
        >>> (df == df2).all(None)
        True
    """
    bio = kwargs["path"] = BytesIO()
    def read(self) -> bytes:
        return read_io(self.bio)
    def write(self, path: Union[bytes, int, PathLike]) -> int:
        return open(path, "wb").write(read(self))
    with ExcelWriter(**kwargs) as writer:
        setattr(writer, "bio", bio)
        setattr(writer, "read", MethodType(read, writer))
        setattr(writer, "write", MethodType(write, writer))
        yield writer


def df_to_excel_bytes(
    dfs: Union[DataFrame, dict[str, DataFrame], Iterable[DataFrame]]
) -> bytes:
    """æŠŠ `pandas` çš„ `DataFrame` å¯¹è±¡è½¬æ¢æˆ xlsx æ ¼å¼çš„ Excel æ–‡ä»¶çš„å­—èŠ‚æ•°æ®

    :param dfs: ä¸€ä¸ªæˆ–ä¸€æ‰¹ `pandas` çš„ `DataFrame` å¯¹è±¡
    :return: Excel æ–‡ä»¶çš„å­—èŠ‚æ•°æ®

    Example::
        >>> import pandas as pd
        >>> df = pd.DataFrame([[1,2],[3,4]])
        >>> data = df_to_excel_bytes([df]*10)
        >>> df2 = pd.read_excel(data, sheet_name="5")
        >>> (df == df2).all(None)
        True
    """
    dfd: dict[str, DataFrame]
    if isinstance(dfs, DataFrame):
        dfd = {"Sheet1": dfs}
    elif isinstance(dfs, dict):
        dfd = dfs
    else:
        dfd = {str(i): df for i, df in enumerate(dfs)}

    with ctx_df_to_excel_bytes() as writer:
        for old_k, df in dfd.items():
            # æŠŠåç§° old_k ä¸­çš„æ‰€æœ‰éæ³•å­—ç¬¦å„è‡ªè½¬æ¢æˆä¸‹åˆ’çº¿ _
            k = old_k.translate(EXCEL_SHEETNAME_INVALID_CHARS_TRANSTABLE)
            if old_k != k:
                warn(f"Illegal characters found in sheetname, convert {old_k!r} to {k!r}")

            index, columns = df.index, df.columns
            nrows, ncols = len(index), len(columns)
            index_nlevel, columns_nlevel = index.nlevels, columns.nlevels
            # whether_output_index åˆ¤åˆ«äº†æ˜¯å¦è¦åœ¨ Excel ä¸­è¾“å‡º index
            # åªæœ‰å½“ index å’Œ columns çš„ level å±‚æ•°éƒ½æ˜¯ 1ï¼Œå¹¶ä¸” index çš„å¼€å§‹å€¼ start ä¸º 0 ä¸”
            # æ­¥è¿› step çš„å€¼æ˜¯ 1ï¼Œæ‰ä¸éœ€è¦è¾“å‡ºç´¢å¼•ã€‚
            # TIPS: å¦‚æœ columns çš„ level å±‚æ•°å¤§äº 1ï¼Œ`pandas` è§„å®šå¿…é¡»è¾“å‡º index
            whether_output_index = not (
                columns_nlevel == 1 and
                index_nlevel == 1 and
                isinstance(index, RangeIndex) and
                index.start == 0 and
                index.step == 1
            )

            # rng_row_step: é™¤å» columns çš„è¾“å‡ºåï¼Œè¿˜å‰©å¤šå°‘è¡Œå¯ä¾›æ•°æ®è¾“å‡º
            rng_row_step: int
            # rng_col_step: é™¤å» index çš„è¾“å‡ºåï¼ˆä¹Ÿå¯èƒ½ä¸è¾“å‡ºï¼‰ï¼Œè¿˜å‰©å¤šå°‘åˆ—å¯ä¾›æ•°æ®è¾“å‡º
            rng_col_step: int
            if whether_output_index:
                # å¦‚æœ columns çš„ level å±‚æ•°å¤§äº 1ï¼Œåˆ™ä¼šå¤šè¾“å‡ºä¸€ç©ºç™½è¡Œ
                if columns_nlevel > 1:
                    rng_row_step = SHEET_MAX_NROWS - columns_nlevel - 1
                else:
                    rng_row_step = SHEET_MAX_NROWS - 1
                rng_col_step = SHEET_MAX_NCOLS - index_nlevel
            else:
                rng_row_step = SHEET_MAX_NROWS - 1
                rng_col_step = SHEET_MAX_NCOLS
            rng_row = range(0, nrows, rng_row_step)
            rng_col = range(0, ncols, rng_col_step)

            # suffix_templateï¼š å¦‚æœçš„è¡Œæˆ–åˆ—è¿‡å¤§ï¼Œå¯¼è‡´ä¸€å¼ å·¥ä½œè¡¨ä¸èƒ½è¾“å‡ºï¼Œåˆ™è¦
            #     æ‹†åˆ†æˆå‡ å¼ å·¥ä½œè¡¨ï¼Œä¸ºæ­¤éœ€è¦ä¸ºåŒä¸€ä¸ª DataFrame è¾“å‡ºçš„å¤šä¸ªå·¥ä½œè¡¨
            #     æ·»åŠ åç¼€ï¼Œæœ€åçš„æ ¼å¼å½¢å¦‚ï¼ˆ{name}è¡¨ç¤ºå¼•ç”¨ï¼‰
            #         {è¡¨å}^{è¡Œåˆ‡åˆ†åºå·}_{åˆ—åˆ‡åˆ†åºå·}
            #     å‡è®¾æŸä¸ª DataFrame è¢«åˆ‡åˆ†æˆäº†
            #         sheet^0_0, sheet^0_1, sheet^1_0, sheet^1_0
            #     é‚£ä¹ˆæ•°æ®åœ¨åŸæ¥çš„ DataFrame ä¸­çš„åˆ†å¸ƒåˆ™æ˜¯
            #         |sheet^0_0 | sheet^0_1 |
            #         |â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”|â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”|
            #         |sheet^1_0 | sheet^1_0 |
            suffix_template = ""
            # TIPS: å·¥ä½œè¡¨æœ€å¤šåªèƒ½æœ‰ 31 ä¸ªå­—ç¬¦ï¼Œå› æ­¤å¦‚æœæ·»åŠ åç¼€åï¼Œå¯¼è‡´å’Œè¡¨åçš„ç»„åˆå¤šäº 
            #     31 å­—ç¬¦ï¼Œé‚£ä¹ˆå°±è¦ä»è¡¨åçš„å°¾éƒ¨å»æ‰ä¸€äº›å­—ç¬¦
            suffix_len = 0
            if len(rng_row) > 1:
                q, r = divmod(len(rng_row), 16)
                l = q + (r > 0)
                suffix_template += "^{0:0%dx}" % l
                suffix_len += l + 1
            if len(rng_col) > 1:
                q, r = divmod(len(rng_col), 16)
                l = q + (r > 0)
                suffix_template += "_{1:0%dx}" % l
                suffix_len += l + 1
            if suffix_len > 31:
                raise RuntimeError(f"DataFrame is too large: {old_k!r}")

            if suffix_len:
                for i, row0 in enumerate(rng_row):
                    for j, col0 in enumerate(rng_col):
                        suffix = suffix_template.format(i, j)
                        key = k[:31-suffix_len] + suffix
                        warn(f"DataFrame is too large, generate sub-sheet: {key!r} (of {old_k!r})")
                        df.iloc[row0:row0+rng_row_step, col0:col0+rng_col_step].to_excel(
                            writer, index=whether_output_index, sheet_name=key)
            else:
                key = k[:31]
                if key != k:
                    warn(f"Sheetname is too long, convert {old_k!r} to {key!r}")
                if key == "":
                    key = "Sheet1"
                df.to_excel(writer, index=whether_output_index, sheet_name=key)

    return writer.read()


def pandas_read_sqls(
    sqls: Union[str, dict[str, str], Iterable[str]],
    con,
    read_workers: int = -1,
) -> dict[str, DataFrame]:
    """è¯»å–ä¸€æ‰¹ SQL æŸ¥è¯¢è¯­å¥ï¼Œæ¯ä¸ª SQL çš„æŸ¥è¯¢ç»“æœéƒ½æ˜¯ä¸€ä¸ª `pandas` çš„ `DataFrame` å¯¹è±¡ã€‚

    :param sqls: ä¸€ä¸ªæˆ–ä¸€æ‰¹ SQL æŸ¥è¯¢è¯­å¥
    :param con: SQL æŸ¥è¯¢çš„æœåŠ¡å™¨è¿æ¥
        SQLAlchemy connectable, str, or sqlite3 connection
        Using SQLAlchemy makes it possible to use any DB supported by that
        library. If a DBAPI2 object, only sqlite3 is supported. The user is responsible
        for engine disposal and connection closure for the SQLAlchemy connectable; str
        connections are closed automatically. See
        `here <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.
    :param read_workers: å¹¶å‘çš„æŸ¥è¯¢æ•°
        - å¦‚æœå°äº 0 æˆ–ç­‰äº 1ï¼Œåˆ™å¹¶å‘æ•°ä¸º 1ï¼Œå³ä¸å¹¶å‘
        - å¦‚æœç­‰äº 0ï¼Œåˆ™ç”¨ ThreadPoolExecutor é»˜è®¤çš„å¹¶å‘æ•°
        - å¦‚æœå¤§äº 0ï¼Œåˆ™æ•°å€¼å°±æ˜¯å¹¶å‘æ•°

    :return: è¿”å›å€¼çš„å†…å®¹å–å†³äºå‚æ•° `sqls`ï¼Œå…·ä½“ä¸º
        if isinstance(sqls, str):
            return {"": pandas.read_sql(sqls, con)}
        elif isinstance(sqls, dict):
            return {k: pandas.read_sql(sql, con) for k, sql in sqls.items()}
        else:
            return {str(i): pandas.read_sql(sql, con) for i, sql in enumerate(sqls)}
    """
    if isinstance(sqls, str):
        return {"": read_sql(sqls, con)}
    else:
        if not isinstance(sqls, dict):
            sqls = dict((str(i), sql) for i, sql in enumerate(sqls))
        sqls = cast(dict[str, str], sqls)
        if read_workers < 0 or read_workers == 1:
            return {k: read_sql(sql, con) for k, sql in sqls.items()}
        else:
            with ThreadPoolExecutor(
                None if read_workers == 0 else min(read_workers, len(sqls))
            ) as worker:
                df_iter = worker.map(lambda sql: read_sql(sql, con), sqls)
            return {k: df for k, df in zip(sqls, df_iter)}


def sql_to_excel_bytes(
    sqls: Union[str, dict[str, str], Iterable[str]],
    con,
    read_workers: int = -1,
) -> bytes:
    """æ‰§è¡Œä¸€äº› SQL æŸ¥è¯¢è¯­å¥ï¼Œå¹¶æŠŠæŸ¥è¯¢ç»“æœä¿å­˜åˆ°åŒä¸€ä¸ª xlsx æ ¼å¼çš„ Excel æ–‡ä»¶ä¸­ï¼Œ
    ç„¶åè¯»å–è¿™ä¸ª Excel æ–‡ä»¶å¹¶è¿”å›å­—èŠ‚æ•°æ®ã€‚

    :param sqls: ä¸€ä¸ªæˆ–ä¸€æ‰¹ SQL æŸ¥è¯¢è¯­å¥ï¼Œå·¥ä½œè¡¨åçš„ç¡®å®šæ–¹å¼å¦‚ä¸‹ï¼š
        - å¦‚æœ `sql` æ˜¯ strï¼Œåˆ™å·¥ä½œè¡¨åä¸º "Sheet1"ï¼Œ`sqls`æ˜¯ç›¸åº”çš„ SQL
        - å¦‚æœ `sql` æ˜¯ dictï¼Œ åˆ™å­—å…¸çš„é”®æ˜¯å·¥ä½œè¡¨åï¼Œå€¼æ˜¯ç›¸åº”çš„ SQL
            > æ³¨æ„ï¼šæ¯ä¸ªå·¥ä½œè¡¨çš„åå­—ï¼Œä¸å…è®¸åŒ…å«è¿™äº›å­—ç¬¦ä¹‹ä¸€ []:*?/\\ ï¼Œ
                å¦‚æœåŒ…å«ï¼Œåˆ™ä¼šè¢«è‡ªåŠ¨æ›¿æ¢æˆ _
        - å¦åˆ™ `sql` å°±æ˜¯å¯è¿­ä»£å¯¹è±¡ï¼Œ åˆ™å€¼æ˜¯ SQLï¼Œåºå·ï¼ˆä»0å¼€å§‹é€’å¢ï¼‰æ˜¯ç›¸åº”çš„å·¥ä½œè¡¨å
        > æ³¨æ„ï¼šæ¯ä¸ª SQL æŸ¥è¯¢è¿”å›çš„æ•°æ®é‡ï¼Œè¡Œæ•°å°½é‡ <= 1048575(==2**20-1ï¼Œç¬¬ 1 è¡Œæ˜¯è¡¨å¤´)ï¼Œ
            åˆ—æ•°æœ€å¥½ <= 16384 (==2**14)ï¼Œå¦åˆ™ä¼šè¢«è‡ªåŠ¨æ‹†åˆ†
    :param con: SQL æŸ¥è¯¢çš„æœåŠ¡å™¨è¿æ¥
        SQLAlchemy connectable, str, or sqlite3 connection
        Using SQLAlchemy makes it possible to use any DB supported by that
        library. If a DBAPI2 object, only sqlite3 is supported. The user is responsible
        for engine disposal and connection closure for the SQLAlchemy connectable; str
        connections are closed automatically. See
        `here <https://docs.sqlalchemy.org/en/13/core/connections.html>`_.
    :param read_workers: å¹¶å‘çš„æŸ¥è¯¢æ•°
        - å¦‚æœå°äº 0 æˆ–ç­‰äº 1ï¼Œåˆ™å¹¶å‘æ•°ä¸º 1ï¼Œå³ä¸å¹¶å‘
        - å¦‚æœç­‰äº 0ï¼Œåˆ™ç”¨ ThreadPoolExecutor é»˜è®¤çš„å¹¶å‘æ•°
        - å¦‚æœå¤§äº 0ï¼Œåˆ™æ•°å€¼å°±æ˜¯å¹¶å‘æ•°

    :return: Excel æ–‡ä»¶æ•°æ®ï¼Œbytes å½¢å¼

    Example::
        å¯ä»¥ç”¨ sqllite3 è¿›è¡Œæµ‹è¯•
        >>> sql = '''\\
        ... with recursive range(x) as (
        ...     values(0)
        ...     union all
        ...     select x + 1 from range where x < POW(2, 21)
        ... )
        ... select * from range;'''
        >>> data = sql_to_excel_bytes([sql]*2, "sqlite:///:memory:")
        ...
        >>> import pandas as pd
        >>> df0 = pd.read_excel(data, sheet_name="0^0")
        >>> df1 = pd.read_excel(data, sheet_name="0^1")
        >>> df2 = pd.read_excel(data, sheet_name="0^2")
        >>> df = pd.concat([df0, df1, df2], ignore_index=True)
        >>> (df.x == range(2 ** 21 + 1)).all()
        True
    """
    dfs = pandas_read_sqls(sqls, con, read_workers)
    return df_to_excel_bytes(dfs)


if __name__ == "__main__":
    import doctest
    doctest.testmod()


```

## æ‰©å±•é˜…è¯»

### 1. æŠŠ `pandas` çš„ `DataFrame` å¯¼å‡ºå„ç§ç¼–ç æ ¼å¼çš„å­—ç¬¦ä¸²

å¦‚æœæ¯ä¸ª <kbd>pandas</kbd> çš„ `DataFrame`ï¼Œå„è‡ªå¯¼å‡ºåˆ°ä¸åŒçš„ç›®æ ‡ï¼Œé‚£ä¹ˆå¯ä»¥è¿ç”¨[ç­–ç•¥æ¨¡å¼](https://www.runoob.com/design-pattern/strategy-pattern.html)ï¼Œå®ç°ä¸€ä¸ªç‰¹åˆ«ç®€å•çš„ç»Ÿä¸€å¤„ç†å‡½æ•°ï¼Œè¿”å›å¯¼å‡ºçš„ `bytes` æˆ– `str`ã€‚ 

<div align="center">
<strong>pandas_df_2_string</strong> å‡½æ•°çš„å‚æ•°å’Œè¿”å›å€¼ç±»å‹

|    | filetype     | outtype   | RETURN TYPE   |
|---:|:-------------|:----------|:--------------|
|  0 | `'csv'`      | bytes     | bytes         |
|  1 | `'csv'`      | str       | str           |
|  2 | `'csv'`      | None      | str           |
|  3 | `'excel'`    | bytes     | bytes         |
|  4 | `'excel'`    | None      | bytes         |
|  5 | `'feather'`  | bytes     | bytes         |
|  6 | `'feather'`  | None      | bytes         |
|  7 | `'hdf'`      | bytes     | bytes         |
|  8 | `'hdf'`      | None      | bytes         |
|  9 | `'html'`     | bytes     | bytes         |
| 10 | `'html'`     | str       | str           |
| 11 | `'html'`     | None      | str           |
| 12 | `'json'`     | bytes     | bytes         |
| 13 | `'json'`     | str       | str           |
| 14 | `'json'`     | None      | str           |
| 15 | `'latex'`    | bytes     | bytes         |
| 16 | `'latex'`    | str       | str           |
| 17 | `'latex'`    | None      | str           |
| 18 | `'markdown'` | bytes     | bytes         |
| 19 | `'markdown'` | str       | str           |
| 20 | `'markdown'` | None      | str           |
| 21 | `'parquet'`  | bytes     | bytes         |
| 22 | `'parquet'`  | None      | bytes         |
| 23 | `'pickle'`   | bytes     | bytes         |
| 24 | `'pickle'`   | None      | bytes         |
| 25 | `'stata'`    | bytes     | bytes         |
| 26 | `'stata'`    | None      | bytes         |
| 27 | `'string'`   | bytes     | bytes         |
| 28 | `'string'`   | str       | str           |
| 29 | `'string'`   | None      | str           |
| 30 | `'xml'`      | bytes     | bytes         |
| 31 | `'xml'`      | str       | str           |
| 32 | `'xml'`      | None      | str           |
</div>

```python pandas_df_2_string.py
#!/usr/bin/env python3
# coding: utf-8

__author__ = "ChenyangGao <https://chenyanggao.github.io/>"
__version__ = (0, 1)
__all__ = ["pandas_df_2_string"]

from io import BytesIO, StringIO
from os import remove
from tempfile import mktemp
from uuid import uuid4


def _to_bytes(write, /, **kwds):
    fio = BytesIO()
    write(fio, **kwds)
    fio.seek(0)
    return fio.read()

def _to_str(write, /, **kwds):
    fio = StringIO()
    write(fio, **kwds)
    fio.seek(0)
    return fio.read()

def _to_str_bytes(write, /, **kwds):
    return _to_str(write, **kwds).encode(encoding="utf-8")

def _call_none(write, /, **kwds):
    return write(None, **kwds)

def _to_hdf_bytes(write, /, **kwds):
    kwds.setdefault("key", "default")
    path = mktemp(str(uuid4()))
    try:
        write(path, **kwds)
        return open(path, "rb").read()
    finally:
        try:
            remove(path)
        except:
            pass

MAP = {
    "csv": {
        bytes: _to_bytes,
        str: _to_str,
        None: _call_none,
    },
    "excel": {
        bytes: _to_bytes,
        None: _to_bytes,
    },
    "feather": {
        bytes: _to_bytes,
        None: _to_bytes,
    },
    "hdf": {
        bytes: _to_hdf_bytes,
        None: _to_hdf_bytes,
    },
    "html": {
        bytes: _to_str_bytes,
        str: _to_str,
        None: _call_none,
    },
    "json": {
        bytes: _to_bytes,
        str: _to_str,
        None: _call_none,
    },
    "latex": {
        bytes: _to_str_bytes,
        str: _to_str,
        None: _call_none,
    },
    "markdown": {
        bytes: _to_str_bytes,
        str: _to_str,
        None: _call_none,
    },
    "parquet": {
        bytes: _to_bytes,
        None: _call_none,
    },
    "pickle": {
        bytes: _to_bytes,
        None: _to_bytes,
    },
    "stata": {
        bytes: _to_bytes,
        None: _call_none,
    },
    "string": {
        bytes: _to_str_bytes,
        str: _to_str,
        None: _call_none,
    },
    "xml": {
        bytes: _to_bytes,
        str: _to_str,
        None: _call_none,
    },
}


def pandas_df_2_string(df, filetype="csv", outtype=None, **kwds):
    """æŠŠ dataframe å¯¼å‡ºä¸º bytes æˆ– str

    :param df: pandas.DataFrame å¯¹è±¡
    :param filetype: æ–‡ä»¶æ ¼å¼ï¼Œå¯ä»¥å–å€¼å¦‚ä¸‹ï¼š
        'csv', 'excel', 'feather', 'hdf', 'html', 'json', 'latex', 
        'markdown', 'parquet', 'pickle', 'stata', 'string', 'xml'
    :param outtype: è¾“å‡ºæ ¼å¼ï¼Œå¯ä»¥å–å€¼å¦‚å³ï¼šbytes, str, None
        > æ³¨æ„ï¼šbytes å’Œ None éƒ½æ˜¯æœ‰æ•ˆçš„ï¼Œä½†æ˜¯ str åªå¯¹æŸäº› filetype æœ‰æ•ˆ
    :param kwds: è°ƒç”¨çš„æ–¹æ³•ä¼šè½å®åˆ° getattr(pandas.DataFrame, 'to_' + filetype)
        ï¼Œè€Œ `kwds` æ˜¯ä¼ ç»™è¿™ä¸ªæ–¹æ³•çš„å…¶å®ƒå…³é”®å­—å‚æ•°

    :return: æ ¹æ® outtype çš„å€¼æ¥å†³å®šï¼š
        - outtype æ˜¯ bytesï¼Œè¾“å‡ºç±»å‹ bytes
        - outtype æ˜¯ strï¼Œè¾“å‡ºç±»å‹ str
        - outtype æ˜¯ Noneï¼Œè¾“å‡ºç±»å‹ç”±å…·ä½“ filetype å†³å®š
    """
    submap = MAP.get(filetype)
    if submap is None:
        raise ValueError(f"Invalid filetype, expected value in {MAP.keys()}, got {filetype!r}")
    outm = submap.get(outtype)
    if outm is None:
        raise ValueError(f"Invalid outtype for filetype {filetype!r}, expected value in {submap.keys()}, got {outtype!r}")
    method = getattr(df, "to_" + filetype)
    return outm(method, **kwds)
```



### 2. åŸºäºpandaså®ç°ä¸€ä¸ªç®€å•çš„ETLç¨‹åº

æˆ‘ç”¨çš„ <kbd>Python</kbd> å’Œ <kbd>pandas</kbd> ç‰ˆæœ¬å¦‚ä¸‹
```sh
$ python -V
Python 3.9.12
$ python -c "import pandas;print(pandas.__version__)"
1.4.2
```

`ETL` çš„ `extract` è¿™ä¸€æ­¥ï¼Œéœ€è¦å°è£…æ‰€æœ‰ `pandas.read_*` æ–¹æ³•ï¼Œç½—åˆ—å¦‚ä¸‹

```python
import pandas as pd

df = pd.DataFrame(
    [(
        "pandas." + f, 
        pd.__dict__[f].__doc__.split("\n", 2)[1].strip()
    ) for f in dir(pd) if f.startswith("read_")], 
    columns=["è¯»å…¥æ–¹æ³•", "è¯´æ˜"], 
)
print(df.to_markdown())
```

|    | è¯»å…¥æ–¹æ³•              | è¯´æ˜                                                             |
|---:|:----------------------|:-----------------------------------------------------------------|
|  0 | pandas.read_clipboard | Read text from clipboard and pass to read_csv.                   |
|  1 | pandas.read_csv       | Read a comma-separated values (csv) file into DataFrame.         |
|  2 | pandas.read_excel     | Read an Excel file into a pandas DataFrame.                      |
|  3 | pandas.read_feather   | Load a feather-format object from the file path.                 |
|  4 | pandas.read_fwf       | Read a table of fixed-width formatted lines into DataFrame.      |
|  5 | pandas.read_gbq       | Load data from Google BigQuery.                                  |
|  6 | pandas.read_hdf       | Read from the store, close it if we opened it.                   |
|  7 | pandas.read_html      | Read HTML tables into a ``list`` of ``DataFrame`` objects.       |
|  8 | pandas.read_json      | Convert a JSON string to pandas object.                          |
|  9 | pandas.read_orc       | Load an ORC object from the file path, returning a DataFrame.    |
| 10 | pandas.read_parquet   | Load a parquet object from the file path, returning a DataFrame. |
| 11 | pandas.read_pickle    | Load pickled pandas object (or any object) from file.            |
| 12 | pandas.read_sas       | Read SAS files stored as either XPORT or SAS7BDAT format files.  |
| 13 | pandas.read_spss      | Load an SPSS file from the file path, returning a DataFrame.     |
| 14 | pandas.read_sql       | Read SQL query or database table into a DataFrame.               |
| 15 | pandas.read_sql_query | Read SQL query into a DataFrame.                                 |
| 16 | pandas.read_sql_table | Read SQL database table into a DataFrame.                        |
| 17 | pandas.read_stata     | Read Stata file into DataFrame.                                  |
| 18 | pandas.read_table     | Read general delimited file into DataFrame.                      |
| 19 | pandas.read_xml       | Read XML document into a ``DataFrame`` object.                   |

è€Œåš `ETL` çš„ `load` è¿™ä¸€æ­¥ï¼Œéœ€è¦å°è£…æ‰€æœ‰ `pandas.DataFrame.to_*` æ–¹æ³•ï¼Œç½—åˆ—å¦‚ä¸‹

```python
import pandas as pd

df = pd.DataFrame(
    [(
        "pandas.DataFrame." + f, 
        getattr(pd.DataFrame, f).__doc__.split("\n", 2)[1].strip()
    ) for f in dir(pd.DataFrame) if f.startswith("to_")], 
    columns=["å†™å‡ºæ–¹æ³•", "è¯´æ˜"], 
)
print(df.to_markdown())
```

|    | å†™å‡ºæ–¹æ³•                      | è¯´æ˜                                                                  |
|---:|:------------------------------|:----------------------------------------------------------------------|
|  0 | pandas.DataFrame.to_clipboard | Copy object to the system clipboard.                                  |
|  1 | pandas.DataFrame.to_csv       | Write object to a comma-separated values (csv) file.                  |
|  2 | pandas.DataFrame.to_dict      | Convert the DataFrame to a dictionary.                                |
|  3 | pandas.DataFrame.to_excel     | Write object to an Excel sheet.                                       |
|  4 | pandas.DataFrame.to_feather   | Write a DataFrame to the binary Feather format.                       |
|  5 | pandas.DataFrame.to_gbq       | Write a DataFrame to a Google BigQuery table.                         |
|  6 | pandas.DataFrame.to_hdf       | Write the contained data to an HDF5 file using HDFStore.              |
|  7 | pandas.DataFrame.to_html      | Render a DataFrame as an HTML table.                                  |
|  8 | pandas.DataFrame.to_json      | Convert the object to a JSON string.                                  |
|  9 | pandas.DataFrame.to_latex     | Render object to a LaTeX tabular, longtable, or nested table/tabular. |
| 10 | pandas.DataFrame.to_markdown  | Print DataFrame in Markdown-friendly format.                          |
| 11 | pandas.DataFrame.to_numpy     | Convert the DataFrame to a NumPy array.                               |
| 12 | pandas.DataFrame.to_parquet   | Write a DataFrame to the binary parquet format.                       |
| 13 | pandas.DataFrame.to_period    | Convert DataFrame from DatetimeIndex to PeriodIndex.                  |
| 14 | pandas.DataFrame.to_pickle    | Pickle (serialize) object to file.                                    |
| 15 | pandas.DataFrame.to_records   | Convert DataFrame to a NumPy record array.                            |
| 16 | pandas.DataFrame.to_sql       | Write records stored in a DataFrame to a SQL database.                |
| 17 | pandas.DataFrame.to_stata     | Export DataFrame object to Stata dta format.                          |
| 18 | pandas.DataFrame.to_string    | Render a DataFrame to a console-friendly tabular output.              |
| 19 | pandas.DataFrame.to_timestamp | Cast to DatetimeIndex of timestamps, at *beginning* of period.        |
| 20 | pandas.DataFrame.to_xarray    | Return an xarray object from the pandas object.                       |
| 21 | pandas.DataFrame.to_xml       | Render a DataFrame to an XML document.                                |

åœ¨ `ETL` çš„ä¸‰ä¸ªæ­¥éª¤ä¸­ï¼Œæœ€é‡è¦çš„æ˜¯ `T` (transform)ã€‚æˆ‘ä¹‹å‰çš„é¡¹ç›®ï¼Œåœ¨ `transform` è¿™ä¸€æ­¥ï¼Œä¸“é—¨å¼€å‘äº†ä¸€ä¸ª [DSL(Domain-specific language)](https://en.wikipedia.org/wiki/Domain-specific_language)ï¼Œä¼šæŠŠä¸€ç§ç›¸å¯¹ç®€å•çš„è¯­è¨€ç¿»è¯‘æˆ <kbd>Python</kbd> å’Œ <kbd>pandas</kbd> æ“ä½œã€‚ä½†æ˜¯ä½œä¸ºç¤ºä¾‹æ¥è¯´ï¼Œè¿™è¿‡äºå¤æ‚äº†ï¼Œç­‰ä¸‹æ¬¡åˆ†äº«å¦‚ä½•**å¼€å‘è„šæœ¬è¯­è¨€**æ—¶ï¼Œæˆ‘å†å±•å¼€è¿™ä¸ªä¾‹å­ã€‚
ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘æŠŠ `ETL` ç®€åŒ–æˆå¦‚ä¸‹è¿™æ ·ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨

```python
from contextlib import contextmanager
from typing import Any, Callable

from pandas.core.frame import DataFrame

@contextmanager
def ctx_dataframe_as_pipe(
    read: Callable[[], DataFrame], 
    write: Callable[[DataFrame], Any], 
):
    df = read()
    yield df
    write(df)
```

å…¶ä¸­ `read` å’Œ `write` åœ¨è°ƒç”¨å‡½æ•°æ—¶ä¼ å…¥ï¼Œè¯·ç¡®ä¿ä¼ å…¥çš„å‚æ•°ç±»å‹æ­£ç¡®ï¼Œå¿…é¡»æ˜¯ä¸¤ä¸ªå¯è°ƒç”¨å¯¹è±¡ï¼Œå¦‚æœå®ƒä»¬å„è‡ªè¿˜æœ‰å…¶å®ƒå‚æ•°ï¼Œè¯·æå‰ç”¨åå‡½æ•° [functools.partial](https://docs.python.org/3/library/functools.html#functools.partial) è¿›è¡Œæ†ç»‘ã€‚






---

æœªå®Œå¾…ç»­

